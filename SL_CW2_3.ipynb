{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SQv4JIhc0p0Z"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wn--uizx1skN"
   },
   "source": [
    "# Data Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pEuL47lA1vOf"
   },
   "outputs": [],
   "source": [
    "def sample_data(m, n, winnow = False):\n",
    "  #returns dataset sampled uniformly at random from {-1,1}^n of dimension n and size m\n",
    "  if winnow:\n",
    "    return np.random.choice([0,1], size = (m, n))\n",
    "  else:\n",
    "    return np.random.choice([-1,1], size = (m, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3VVGi7a5CgYl"
   },
   "outputs": [],
   "source": [
    "def gen_error(y_hat, y):\n",
    "  #calculates generalisation error of prediction\n",
    "  return  1 - (y_hat == y).sum()/y_hat.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FsE2n6BV1SMh"
   },
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "B218L5ZOJ6lD"
   },
   "outputs": [],
   "source": [
    "def perceptron(X_train, X_test):\n",
    "  \n",
    "    w = np.ones(X_train.shape[1])\n",
    "    sign = lambda x: -1 if x <= 0 else 1\n",
    "    #loop through training data\n",
    "    for train_index in range(X_train.shape[0]):\n",
    "    \n",
    "    #PREDICTION STEP\n",
    "        y_hat = sign(w.T @ X_train[train_index, :])\n",
    "    #UPDATE STEP \n",
    "        if X_train[train_index, 0] == y_hat:\n",
    "            continue\n",
    "        else:\n",
    "            w += X_train[train_index, 0] * X_train[train_index, :]\n",
    "\n",
    "\n",
    "\n",
    "    y_hat = np.array([w.T @ X_test[i,:] for i in range(X_test.shape[0])])\n",
    "    y_hat = np.array(list(map(sign , y_hat)))\n",
    "  \n",
    "    return gen_error(y_hat, X_test[:, 0])\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8h2lsy61SUg"
   },
   "source": [
    "# Winnow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LiTRikWpaugS"
   },
   "outputs": [],
   "source": [
    "def winnow(X_train, X_test):\n",
    "    #train winnow classifier and calculate generalisation error on test set\n",
    "    n = X_train.shape[1]\n",
    "    w = np.ones(n)\n",
    "    pred = lambda x: 0 if x < n else 1\n",
    "  \n",
    "    #loop through training data\n",
    "    for train_index in range(X_train.shape[0]):\n",
    "    \n",
    "    #PREDICTION STEP\n",
    "\n",
    "        y_hat = pred(w.T @ X_train[train_index, :])\n",
    "    \n",
    "        y = X_train[train_index, 0]\n",
    "    \n",
    "    #UPDATE STEP\n",
    "        if y == y_hat:\n",
    "            continue\n",
    "        else: #if mistake, apply update rule for each element of w\n",
    "            for i in range(len(w)):\n",
    "                w[i] = w[i]*(2.0**((y - y_hat)*X_train[train_index, i]))\n",
    "\n",
    "    y_hat = np.array([w.T @ X_test[i,:] for i in range(X_test.shape[0])])\n",
    "    y_hat = np.array(list(map(pred , y_hat)))\n",
    "  \n",
    "    return gen_error(y_hat, X_test[:, 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmuuvcxW1Sa4"
   },
   "source": [
    "# Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bwklx2C-_umC"
   },
   "outputs": [],
   "source": [
    "def least_squares(X_train, X_test):\n",
    "  #trains a least squares classifier on X_train and predicts on X_test with sign(w^T X_test)\n",
    "  #returns generalisation error of the model\n",
    "    w = np.linalg.lstsq(X_train, X_train[:, 0], rcond = None)[0]\n",
    "    y_hat = np.array([w.T @ X_test[i,:] for i in range(X_test.shape[0])])\n",
    "    y_hat = np.array(list(map(lambda x: -1 if x < 0 else (1 if x > 0 else np.random.choice([-1,1])), y_hat)))\n",
    "\n",
    "    return gen_error(y_hat, X_test[:, 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5paXQnT11PLW"
   },
   "source": [
    "# 1-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8un3InWb0v8E"
   },
   "outputs": [],
   "source": [
    "def one_NN_helper(X_train, y_train, x_test):\n",
    "    distances = np.linalg.norm(X_train - x_test, axis = 1)#finds euclidean distances between a point x_test and every training point\n",
    "\n",
    "    nn_index = distances.argmin() #find index of nearest neighbour (min distance), in the event of a tie, the first of the nearest neighbours is chosen\n",
    "    pred = y_train[nn_index] #find corresponding classes of nearest neighbour\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zeEXY2OV1i03"
   },
   "outputs": [],
   "source": [
    "def one_NN(X_train, X_test):\n",
    "  #Calculates generalisation error for 1-NN model given a training set and test set\n",
    "    y_hat = np.fromiter((one_NN_helper(X_train, X_train[:,0], x_test) for x_test in X_test), float)  \n",
    "\n",
    "    return gen_error(y_hat, X_test[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkK3aniS_ij6"
   },
   "source": [
    "# Estimating Sample Complexity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NWQVbRYDrIr4"
   },
   "outputs": [],
   "source": [
    "models = [least_squares, perceptron, winnow, one_NN]\n",
    "model_names = ['least_squares', 'perceptron', 'winnow', '1-NN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "M1DEwoafxs4j"
   },
   "outputs": [],
   "source": [
    "def mean_gen_error(model, m, n, train_iter, test_size):\n",
    "    #returns mean generalisation error for model by iteratively sampling training and test sets, training the model and calculating the generalisation error, returns the mean error from the runs\n",
    "    er = []\n",
    "    for _ in range(train_iter):\n",
    "        if model == winnow:\n",
    "            train = sample_data(m, n, winnow = True)\n",
    "            test = sample_data(test_size, n, winnow = True)\n",
    "        else:\n",
    "            train = sample_data(m, n)\n",
    "            test = sample_data(test_size, n)\n",
    "        er.append(model(train, test))\n",
    "    return np.mean(er)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "BS5xkIMbo9-1"
   },
   "outputs": [],
   "source": [
    "def estimate_m_range(model, n = 100):\n",
    "  #given that we intend on finding our sample complexities using binary search, we want to know, roughly, where to set our upper limit for the search. \n",
    "    for m in range(1, 1000, 100):\n",
    "        er = mean_gen_error(model, m, n, 5, 1000)\n",
    "        if er <= 0.1:\n",
    "            return m\n",
    "    return 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Y1p6nqsqkHt",
    "outputId": "851f7688-7291-4528-f901-101e7e2215d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper limit for m model least_squares:  101\n",
      "Upper limit for m model perceptron:  201\n",
      "Upper limit for m model winnow:  101\n",
      "Upper limit for m model 1-NN:  5000\n"
     ]
    }
   ],
   "source": [
    "#estimate upper limits for binary search\n",
    "for i in range(len(models)):\n",
    "    print(f'Upper limit for m model {model_names[i]}:  {estimate_m_range(models[i])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "EciLV8Eno0pQ"
   },
   "outputs": [],
   "source": [
    "def binary_search(model,n, train_iter, test_size, high):\n",
    "  #for a given n, perform a binary search over values of m, searching for sample complexity value\n",
    "    low = 1\n",
    "    gen_error = 1\n",
    "    #first check for 1-NN that our upper limit for the binary search is indeed high enough\n",
    "    if model == one_NN:\n",
    "        while mean_gen_error(model, high, n, train_iter, test_size) > 0.1:\n",
    "            print(f'need upper bound greater than {high}')\n",
    "            high *= 2\n",
    "        \n",
    "    while high - low > 1:\n",
    "        m = (high + low)//2\n",
    "        #get estimated generalisation error for this m\n",
    "        er = mean_gen_error(model, m, n, train_iter, test_size)\n",
    "        \n",
    "       \n",
    "        if er <= 0.1:\n",
    "            #if it is less than 0.1 and the m directly below it has error greater than 0.1, we are done\n",
    "            if mean_gen_error(model, m - 1, n, train_iter, test_size) > 0.1:\n",
    "                return m\n",
    "            else:\n",
    "                high = m\n",
    "        else:\n",
    "            low = m\n",
    "    return high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "WGA0ho9NhIcJ"
   },
   "outputs": [],
   "source": [
    "def estimate_sample_complexity(model,train_iter = 100, test_size = 100, max_n = 100):\n",
    "    #for a given algorithm, loops through each n and finds the sample complexity for that n through binary search\n",
    "    #returns list of sample complexities\n",
    "    ts = time.time()\n",
    "    #takes a model as a parameter, trains\n",
    "    sample_complexity = []\n",
    "    high = estimate_m_range(model, n = max_n)\n",
    "    \n",
    "    for n in range(1, max_n +1):\n",
    "        T = min(2**n,100)\n",
    "        #print(n)\n",
    "        res = binary_search(model,n, train_iter, test_size, high)\n",
    "        sample_complexity.append(res)\n",
    "\n",
    "    print(f'Time Elapsed: {time.time() - ts} seconds')\n",
    "    return sample_complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed: 93.49324774742126 seconds\n"
     ]
    }
   ],
   "source": [
    "#calculate sample complexities for each algorithm\n",
    "#do for n = 1,...,100 for all but 1-NN where we stop at N = 20 due to computation time\n",
    "np.random.seed(0)\n",
    "ls_sample_complexity = estimate_sample_complexity(least_squares, train_iter = 100, test_size = 100, max_n = 100)\n",
    "perceptron_sample_complexity = estimate_sample_complexity(perceptron, train_iter = 100, test_size = 100, max_n = 100)\n",
    "winnow_sample_complexity = estimate_sample_complexity(winnow, train_iter = 100, test_size = 100, max_n = 100)\n",
    "one_nn_sample_complexity = estimate_sample_complexity(one_NN, train_iter = 100, test_size = 100, max_n = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,7))\n",
    "\n",
    "ax.plot(np.arange(1,101), ls_sample_complexity)\n",
    "ax.set_xlabel('n', fontsize= 15);\n",
    "ax.set_ylabel('m', fontsize = 15);\n",
    "ax.set_title('Least Squares Sample Complexity', fontsize = 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,7))\n",
    "\n",
    "ax.plot(np.arange(1,101), perceptron_sample_complexity)\n",
    "ax.set_xlabel('n', fontsize= 15);\n",
    "ax.set_ylabel('m', fontsize = 15);\n",
    "ax.set_title('Perceptron Sample Complexity', fontsize = 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,7))\n",
    "\n",
    "ax.plot(np.arange(1,101), winnow_sample_complexity)\n",
    "ax.set_xlabel('n', fontsize= 15);\n",
    "ax.set_ylabel('m', fontsize = 15);\n",
    "ax.set_title('Winnow Sample Complexity', fontsize = 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,7))\n",
    "\n",
    "ax.plot(np.arange(1,21), one_nn_sample_complexity)\n",
    "ax.set_xlabel('n', fontsize= 15);\n",
    "ax.set_ylabel('m', fontsize = 15);\n",
    "ax.set_title('1-NN Sample Complexity', fontsize = 20);\n",
    "plt.xticks(np.arange(1,21,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature maps for fitting least squares model to sample complexities to estimate how each grows with n\n",
    "\n",
    "def feature_map(X, transform = None):\n",
    "    #adds bias term and transforms features\n",
    "    m = len(X)\n",
    "    bias = np.ones((m,1))\n",
    "    if transform:\n",
    "        X = transform(X).reshape(m, 1)\n",
    "    else:\n",
    "        X = np.array(X).reshape(m, 1)\n",
    "    return np.hstack([bias, X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_OLS(X, y, transform = None):\n",
    "    #fit OLS regression on transformed data\n",
    "    Z = feature_map(X, transform)\n",
    "    w = np.linalg.lstsq(Z, y, rcond = None)[0]\n",
    "    y_hats = np.array(([w.T @ Z[i,:] for i in range(Z.shape[0])]))\n",
    "    return w, y_hats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit least squares OLS\n",
    "# we find our best fitting model is linear so just bias term added\n",
    "w_ls, pred_ls = fit_OLS(np.arange(1,101,1), np.array(ls_sample_complexity).reshape(100,1))\n",
    "print(w_ls)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "#print equation for line of best fit and plot bound lines\n",
    "plt.plot(ls_sample_complexity, label = 'sample complexity')\n",
    "plt.plot(1.1*pred_ls, label = 'upper bound')\n",
    "plt.plot(0.9*pred_ls, label = 'lower bound')\n",
    "ax.set_xlabel('n', fontsize = 10)\n",
    "ax.set_ylabel('m', fontsize = 10)\n",
    "ax.set_title('Bounds on Least Squares Sample Complexity');\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit for perceptron, plot results\n",
    "w_perceptron, pred_perceptron = fit_OLS(np.arange(1,101,1), np.array(perceptron_sample_complexity).reshape(100,1))\n",
    "print(w_perceptron)\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(perceptron_sample_complexity, label = 'sample complexity')\n",
    "plt.plot(1.1*pred_perceptron, label = 'upper bound')\n",
    "plt.plot(0.9*pred_perceptron, label = 'lower bound')\n",
    "ax.set_xlabel('n', fontsize = 10)\n",
    "ax.set_ylabel('m', fontsize = 10)\n",
    "ax.set_title('Bounds on Perceptron Sample Complexity')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit for winnow, find our best fit with log transform of data\n",
    "w_winnow, pred_winnow = fit_OLS(np.arange(1,101,1), np.array(winnow_sample_complexity).reshape(100,1), np.log)\n",
    "print(w_winnow)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.plot(winnow_sample_complexity, label = 'sample complexity')\n",
    "plt.plot(1.15*pred_winnow, label = 'upper bound')\n",
    "plt.plot(0.85*pred_winnow, label = 'lower bound')\n",
    "ax.set_xlabel('n', fontsize = 10)\n",
    "ax.set_ylabel('m', fontsize = 10)\n",
    "ax.set_title('Bounds on Winnow Sample Complexity');\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for 1-nn we transform our data exponentially to give an equation m = a2^(bn)\n",
    "n = np.arange(1,21,1)\n",
    "m = len(n)\n",
    "bias = np.ones((m,1))\n",
    "two_n = np.power(2,n).reshape(m, 1)\n",
    "Z = np.hstack([bias,  n.reshape(m,1)])\n",
    "#Z = n.reshape(m,1)\n",
    "w_nn = np.linalg.lstsq(Z, np.log2(one_nn_sample_complexity), rcond = None)[0]\n",
    "pred_nn = 2**np.array(([w_nn.T @ Z[i,:] for i in range( Z.shape[0])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w_nn)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(one_nn_sample_complexity, label = 'sample complexity')\n",
    "plt.plot(1.15*pred_nn, label = 'upper bound')\n",
    "plt.plot(0.8*pred_nn, label = 'lower bound')\n",
    "\n",
    "ax.set_xlabel('n', fontsize = 10)\n",
    "ax.set_ylabel('m', fontsize = 10)\n",
    "ax.legend();\n",
    "plt.xticks(np.arange(20),np.arange(1,21,1));\n",
    "ax.set_title('Bounds on 1-NN Sample Complexity');\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "SL_CW2_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
